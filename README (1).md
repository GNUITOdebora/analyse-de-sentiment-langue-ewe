# ğŸ§  Analyse de Sentiments du Langage Naturel â€” Langue EWE

> Projet de traitement automatique du langage naturel (NLP) appliquÃ© Ã  la **langue Ewe**, une langue africaine parlÃ©e au Togo, au BÃ©nin et au Ghana.  
> **Ã‰laborÃ© par** : Gnuito DÃ©bora

---

## ğŸ“‹ Table des matiÃ¨res

1. [Contexte et introduction](#contexte-et-introduction)
2. [La langue Ewe](#la-langue-ewe)
3. [Structure du projet](#structure-du-projet)
4. [MÃ©thodologie](#mÃ©thodologie)
5. [RÃ©sultats](#rÃ©sultats)
6. [DÃ©ploiement](#dÃ©ploiement)
7. [Applications potentielles](#applications-potentielles)
8. [Perspectives futures](#perspectives-futures)

---

## ğŸŒ Contexte et introduction

Les dÃ©fis de comprÃ©hension linguistique reprÃ©sentent l'un des domaines les plus complexes de l'intelligence artificielle. Le **Traitement du Langage Naturel (NLP)** est la branche de l'IA qui se concentre sur la capacitÃ© des machines Ã  comprendre, interprÃ©ter et gÃ©nÃ©rer le langage humain.

Ce projet applique le NLP Ã  l'**analyse de sentiment** â€” une tÃ¢che qui consiste Ã  extraire et classifier les opinions (positif, nÃ©gatif, neutre) dans un texte â€” dans le cas particulier de la langue **Ewe**, une langue peu dotÃ©e en ressources numÃ©riques.

---

## ğŸ—£ï¸ La langue Ewe

L'Ã©wÃ© est une langue nigÃ©ro-congolaise parlÃ©e au **Togo**, au **BÃ©nin** et dans le sud-est du **Ghana** par environ **4,5 millions** de locuteurs natifs et un million d'autres comme deuxiÃ¨me langue.

### DÃ©fis spÃ©cifiques au NLP en Ewe

| DÃ©fi | Description |
|------|-------------|
| **TonalitÃ©** | Langue tonale â€” la hauteur de la voix change le sens des mots |
| **Manque de ressources** | Peu de corpus annotÃ©s disponibles ; culture majoritairement orale |
| **Variation dialectale** | Plusieurs dialectes : Guin, Mina, Adja-Ewe, Watsi... |
| **CaractÃ¨res spÃ©ciaux** | Alphabet de 35 lettres avec des caractÃ¨res propres : É£, É”, Æ’, É–, áº½, É”Ìƒ, Ã£... |

> âš ï¸ Contrairement aux langues classiques, les **accents** et **caractÃ¨res spÃ©ciaux** ne peuvent pas Ãªtre supprimÃ©s lors du prÃ©traitement car ils changent le sens des mots. De mÃªme, les **mots d'une seule lettre** doivent Ãªtre conservÃ©s (ex. : `o` exprime la nÃ©gation en Ewe).

---

## ğŸ“ Structure du projet

```
.
â”œâ”€â”€ Projet_analyse_de_sentiments.ipynb   # Notebook principal (exploration, prÃ©traitement, ML)
â”œâ”€â”€ Deploiement.py                       # Application Streamlit de dÃ©monstration
â”œâ”€â”€ vectorizer.pickle                    # Vectoriseur TF-IDF sauvegardÃ©
â””â”€â”€ best_modelNLP.pickle                 # Meilleur modÃ¨le entraÃ®nÃ© sauvegardÃ©
```

---

## ğŸ”¬ MÃ©thodologie

Le projet suit un pipeline en 6 Ã©tapes :

```
1. Collecte & annotation  â†’  2. Exploration  â†’  3. PrÃ©traitement
        â†’  4. Machine Learning  â†’  5. Ã‰valuation  â†’  6. DÃ©ploiement
```

### 1. Collecte et annotation des donnÃ©es

Le dataset combine deux sources :
- **Formulaires en ligne** : avis sur la gastronomie togolaise, le systÃ¨me Ã©ducatif, les habitudes culturelles.
- **Bases existantes** : donnÃ©es issues de diffÃ©rentes sources puis annotÃ©es manuellement.

**CaractÃ©ristiques du dataset :**
- 3 446 exemples, aucune valeur manquante
- 3 classes : `Positive`, `Negative`, `Neutre`
- 6 colonnes : `id`, `Traduction`, `Sentiment`, `Ewe`, `Auteur`, `Document`
- RÃ©partition : NÃ©gatif 35.4% | Positif 35.1% | Neutre 29.5%

### 2. PrÃ©traitement

**Nettoyage :**
- Suppression des nombres
- Suppression des espaces multiples
- Conversion en minuscules
- Ã‰limination de la ponctuation
- Suppression des caractÃ¨res n'existant pas dans l'alphabet Ewe (C, Q, J...)

**Word Embedding :** Vectorisation via **TF-IDF**

### 3. Machine Learning

Plusieurs modÃ¨les ont Ã©tÃ© entraÃ®nÃ©s et comparÃ©s :
`Naive Bayes`, `MLP Classifier`, `SGD SVM`, `Polynomial SVM`, `RBF SVM`, `Linear SVM`

---

## ğŸ“Š RÃ©sultats

### Comparaison des modÃ¨les

| ModÃ¨le | F1 NÃ©gative | F1 Neutre | F1 Positive |
|--------|------------|-----------|-------------|
| Naive Bayes | 0.54 | 0.46 | 0.47 |
| MLP Classifier | 0.63 | 0.51 | 0.66 |
| SGD SVM | 0.64 | 0.47 | 0.68 |
| Polynomial SVM | 0.66 | 0.46 | **0.70** |
| RBF SVM | 0.66 | 0.46 | 0.69 |
| **Linear SVM** | **0.64** | **0.48** | 0.68 |

> ğŸ† Le **Polynomial SVM** obtient les meilleures performances globales, notamment sur la classe Positive (F1 = 0.70). Le modÃ¨le final est sauvegardÃ© dans `best_modelNLP.pickle`.

---

## ğŸš€ DÃ©ploiement

L'application est dÃ©ployÃ©e via **Streamlit**. Elle permet Ã  un utilisateur de saisir un commentaire en langue Ewe et d'obtenir une prÃ©diction de sentiment.

### Lancement

```bash
pip install streamlit scikit-learn nltk
streamlit run Deploiement.py
```

### Pipeline de prÃ©diction dans l'app

```python
# 1. Nettoyage du texte saisi
tmp = re.sub(r'\d+', ' ', text)       # Supprime les nombres
tmp = re.sub(r'\s+', ' ', tmp)        # Supprime les espaces multiples
tmp = tmp.lower()                      # Minuscules
tmp = re.sub(r'[^\w\s]', '', tmp)     # Ã‰limine la ponctuation

# 2. Vectorisation TF-IDF
X = vect.transform([tmp]).toarray()

# 3. PrÃ©diction
pred = model.predict(X)               # â†’ ['Positive'] / ['Negative'] / ['Neutre']
```

### PrÃ©requis

```
streamlit
scikit-learn
nltk
pickle
```

---

## ğŸ’¡ Applications potentielles

- **Marketing et PublicitÃ©** : Analyser les perceptions des consommateurs pour ajuster les stratÃ©gies.
- **Communication et Interaction** : Mieux comprendre les Ã©motions dans les messages et commentaires.
- **Analyse de sondages** : Identifier les attitudes et opinions du public Ã  grande Ã©chelle.

---

## ğŸ”­ Perspectives futures

1. **Ã‰tendre la collecte de donnÃ©es** annotÃ©es dans diffÃ©rents domaines et registres de la langue Ewe pour amÃ©liorer la robustesse du modÃ¨le.
2. **Explorer des approches multilingues** intÃ©grant d'autres langues africaines similaires pour tirer parti des similaritÃ©s linguistiques.

---

## ğŸ‘©â€ğŸ’» Auteure

| Nom | Institution |
|-----|-------------|
| Gnuito DÃ©bora | I3-FSS |

---

*Akpe na mi É–e miaÆ’e É–etsÉ”lemea ta ğŸ™*
